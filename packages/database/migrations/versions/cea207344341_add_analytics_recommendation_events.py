"""add_analytics_recommendation_events

Revision ID: cea207344341
Revises: n1_cloudsql_256_vectors
Create Date: 2026-01-27 20:11:09.847793

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import sqlmodel
import pgvector.sqlalchemy
from pgvector.sqlalchemy import Vector
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'cea207344341'
down_revision: Union[str, Sequence[str], None] = 'n1_cloudsql_256_vectors'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('search_interactions', schema='analytics') as batch_op:
        batch_op.drop_index(batch_op.f('ix_search_interactions_created_at'))
        batch_op.drop_index(batch_op.f('ix_search_interactions_search_id'))
        batch_op.drop_index(batch_op.f('ix_search_interactions_user_id'))

    op.drop_table('search_interactions', schema='analytics')
    with op.batch_alter_table('bookmarkedissue', schema=None) as batch_op:
        batch_op.drop_constraint(batch_op.f('bookmarkedissue_user_id_fkey'), type_='foreignkey')
        batch_op.create_foreign_key(None, 'users', ['user_id'], ['id'], referent_schema='public')

    with op.batch_alter_table('linked_accounts', schema=None) as batch_op:
        batch_op.alter_column('access_token',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=False)
        batch_op.alter_column('refresh_token',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=True)
        batch_op.alter_column('expires_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.alter_column('revoked_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.drop_index(batch_op.f('ix_linked_accounts_provider'))
        batch_op.drop_index(batch_op.f('ix_linked_accounts_user_id'))
        batch_op.create_index(batch_op.f('ix_public_linked_accounts_provider'), ['provider'], unique=False)
        batch_op.create_index(batch_op.f('ix_public_linked_accounts_user_id'), ['user_id'], unique=False)
        batch_op.drop_constraint(batch_op.f('linked_accounts_user_id_fkey'), type_='foreignkey')
        batch_op.create_foreign_key(None, 'users', ['user_id'], ['id'], referent_schema='public')

    with op.batch_alter_table('personalnote', schema=None) as batch_op:
        batch_op.drop_constraint(batch_op.f('personalnote_bookmark_id_fkey'), type_='foreignkey')
        batch_op.create_foreign_key(None, 'bookmarkedissue', ['bookmark_id'], ['id'], referent_schema='public')

    with op.batch_alter_table('session', schema=None) as batch_op:
        batch_op.alter_column('deviation_logged_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.drop_index(batch_op.f('ix_session_user_created'))
        batch_op.drop_index(batch_op.f('ix_session_user_expires'))
        batch_op.drop_constraint(batch_op.f('session_user_id_fkey'), type_='foreignkey')
        batch_op.create_foreign_key(None, 'users', ['user_id'], ['id'], referent_schema='public')

    with op.batch_alter_table('userprofile', schema=None) as batch_op:
        batch_op.alter_column('intent_text',
               existing_type=sa.VARCHAR(),
               nullable=True)
        batch_op.alter_column('resume_uploaded_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.alter_column('github_fetched_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.alter_column('onboarding_completed_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.drop_index(batch_op.f('ix_userprofile_combined_vector'), postgresql_ops={'combined_vector': 'vector_cosine_ops'}, postgresql_with={'m': '16', 'ef_construction': '64'}, postgresql_using='hnsw')
        batch_op.drop_constraint(batch_op.f('userprofile_user_id_fkey'), type_='foreignkey')
        batch_op.create_foreign_key(None, 'users', ['user_id'], ['id'], referent_schema='public')

    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.alter_column('github_node_id',
               existing_type=sa.VARCHAR(),
               nullable=True)
        batch_op.alter_column('github_username',
               existing_type=sa.VARCHAR(),
               nullable=True)
        batch_op.drop_index(batch_op.f('ix_public_user_email'))
        batch_op.drop_index(batch_op.f('ix_public_user_github_node_id'))
        batch_op.drop_constraint(batch_op.f('uq_users_email_provider'), type_='unique')
        batch_op.create_index(batch_op.f('ix_public_users_email'), ['email'], unique=True)
        batch_op.create_index(batch_op.f('ix_public_users_github_node_id'), ['github_node_id'], unique=True)

    with op.batch_alter_table('recommendation_events', schema='analytics') as batch_op:
        batch_op.alter_column('event_type',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=False)
        batch_op.alter_column('issue_node_id',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=False)
        batch_op.alter_column('surface',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=False)
        batch_op.drop_index(batch_op.f('ix_recommendation_events_batch_id'))
        batch_op.drop_index(batch_op.f('ix_recommendation_events_created_at'))
        batch_op.drop_index(batch_op.f('ix_recommendation_events_user_id'))
        batch_op.drop_constraint(batch_op.f('uq_recommendation_events_event_id'), type_='unique')
        batch_op.drop_index(batch_op.f('uq_recommendation_events_impression_composite'), postgresql_where="(event_type = 'impression'::text)")
        batch_op.create_index(batch_op.f('ix_analytics_recommendation_events_created_at'), ['created_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_analytics_recommendation_events_event_type'), ['event_type'], unique=False)
        batch_op.create_index(batch_op.f('ix_analytics_recommendation_events_issue_node_id'), ['issue_node_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analytics_recommendation_events_recommendation_batch_id'), ['recommendation_batch_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analytics_recommendation_events_user_id'), ['user_id'], unique=False)
        batch_op.drop_column('id')

    with op.batch_alter_table('issue', schema='ingestion') as batch_op:
        batch_op.alter_column('tech_stack_weight',
               existing_type=sa.REAL(),
               type_=sa.Float(),
               existing_nullable=False,
               existing_server_default=sa.text("'0'::real"))
        batch_op.alter_column('q_score',
               existing_type=sa.REAL(),
               nullable=True,
               existing_server_default=sa.text("'0'::real"))
        batch_op.alter_column('survival_score',
               existing_type=sa.REAL(),
               nullable=True,
               existing_server_default=sa.text("'0'::real"))
        batch_op.alter_column('github_created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False)
        batch_op.drop_index(batch_op.f('ix_ingestion_issue_content_hash'))
        batch_op.drop_index(batch_op.f('ix_ingestion_issue_github_created_at'))
        batch_op.drop_index(batch_op.f('ix_issue_embedding_hnsw'), postgresql_ops={'embedding': 'vector_cosine_ops'}, postgresql_with={'m': '16', 'ef_construction': '64'}, postgresql_using='hnsw')
        batch_op.drop_column('content_hash')

    with op.batch_alter_table('repository', schema='ingestion') as batch_op:
        batch_op.drop_constraint(batch_op.f('uq_repository_full_name'), type_='unique')
        batch_op.drop_index(batch_op.f('ix_ingestion_repository_full_name'))
        batch_op.create_index(batch_op.f('ix_ingestion_repository_full_name'), ['full_name'], unique=True)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('repository', schema='ingestion') as batch_op:
        batch_op.drop_index(batch_op.f('ix_ingestion_repository_full_name'))
        batch_op.create_index(batch_op.f('ix_ingestion_repository_full_name'), ['full_name'], unique=False)
        batch_op.create_unique_constraint(batch_op.f('uq_repository_full_name'), ['full_name'], postgresql_nulls_not_distinct=False)

    with op.batch_alter_table('issue', schema='ingestion') as batch_op:
        batch_op.add_column(sa.Column('content_hash', sa.VARCHAR(length=64), autoincrement=False, nullable=True))
        batch_op.create_index(batch_op.f('ix_issue_embedding_hnsw'), ['embedding'], unique=False, postgresql_ops={'embedding': 'vector_cosine_ops'}, postgresql_with={'m': '16', 'ef_construction': '64'}, postgresql_using='hnsw')
        batch_op.create_index(batch_op.f('ix_ingestion_issue_github_created_at'), ['github_created_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_ingestion_issue_content_hash'), ['content_hash'], unique=False)
        batch_op.alter_column('github_created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False)
        batch_op.alter_column('survival_score',
               existing_type=sa.REAL(),
               nullable=False,
               existing_server_default=sa.text("'0'::real"))
        batch_op.alter_column('q_score',
               existing_type=sa.REAL(),
               nullable=False,
               existing_server_default=sa.text("'0'::real"))
        batch_op.alter_column('tech_stack_weight',
               existing_type=sa.Float(),
               type_=sa.REAL(),
               existing_nullable=False,
               existing_server_default=sa.text("'0'::real"))

    with op.batch_alter_table('recommendation_events', schema='analytics') as batch_op:
        batch_op.add_column(sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False))
        batch_op.drop_index(batch_op.f('ix_analytics_recommendation_events_user_id'))
        batch_op.drop_index(batch_op.f('ix_analytics_recommendation_events_recommendation_batch_id'))
        batch_op.drop_index(batch_op.f('ix_analytics_recommendation_events_issue_node_id'))
        batch_op.drop_index(batch_op.f('ix_analytics_recommendation_events_event_type'))
        batch_op.drop_index(batch_op.f('ix_analytics_recommendation_events_created_at'))
        batch_op.create_index(batch_op.f('uq_recommendation_events_impression_composite'), ['user_id', 'recommendation_batch_id', 'issue_node_id', 'position', 'surface'], unique=True, postgresql_where="(event_type = 'impression'::text)")
        batch_op.create_unique_constraint(batch_op.f('uq_recommendation_events_event_id'), ['event_id'], postgresql_nulls_not_distinct=False)
        batch_op.create_index(batch_op.f('ix_recommendation_events_user_id'), ['user_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_recommendation_events_created_at'), ['created_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_recommendation_events_batch_id'), ['recommendation_batch_id'], unique=False)
        batch_op.alter_column('surface',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=False)
        batch_op.alter_column('issue_node_id',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=False)
        batch_op.alter_column('event_type',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=False)

    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_public_users_github_node_id'))
        batch_op.drop_index(batch_op.f('ix_public_users_email'))
        batch_op.create_unique_constraint(batch_op.f('uq_users_email_provider'), ['email', 'created_via'], postgresql_nulls_not_distinct=False)
        batch_op.create_index(batch_op.f('ix_public_user_github_node_id'), ['github_node_id'], unique=True)
        batch_op.create_index(batch_op.f('ix_public_user_email'), ['email'], unique=True)
        batch_op.alter_column('github_username',
               existing_type=sa.VARCHAR(),
               nullable=False)
        batch_op.alter_column('github_node_id',
               existing_type=sa.VARCHAR(),
               nullable=False)

    with op.batch_alter_table('userprofile', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(batch_op.f('userprofile_user_id_fkey'), 'users', ['user_id'], ['id'])
        batch_op.create_index(batch_op.f('ix_userprofile_combined_vector'), ['combined_vector'], unique=False, postgresql_ops={'combined_vector': 'vector_cosine_ops'}, postgresql_with={'m': '16', 'ef_construction': '64'}, postgresql_using='hnsw')
        batch_op.alter_column('onboarding_completed_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('github_fetched_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('resume_uploaded_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('intent_text',
               existing_type=sa.VARCHAR(),
               nullable=False)

    with op.batch_alter_table('session', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(batch_op.f('session_user_id_fkey'), 'users', ['user_id'], ['id'])
        batch_op.create_index(batch_op.f('ix_session_user_expires'), ['user_id', 'expires_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_session_user_created'), ['user_id', 'created_at'], unique=False)
        batch_op.alter_column('deviation_logged_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)

    with op.batch_alter_table('personalnote', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(batch_op.f('personalnote_bookmark_id_fkey'), 'bookmarkedissue', ['bookmark_id'], ['id'])

    with op.batch_alter_table('linked_accounts', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(batch_op.f('linked_accounts_user_id_fkey'), 'users', ['user_id'], ['id'], ondelete='CASCADE')
        batch_op.drop_index(batch_op.f('ix_public_linked_accounts_user_id'))
        batch_op.drop_index(batch_op.f('ix_public_linked_accounts_provider'))
        batch_op.create_index(batch_op.f('ix_linked_accounts_user_id'), ['user_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_linked_accounts_provider'), ['provider'], unique=False)
        batch_op.alter_column('revoked_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('expires_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('refresh_token',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=True)
        batch_op.alter_column('access_token',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=False)

    with op.batch_alter_table('bookmarkedissue', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(batch_op.f('bookmarkedissue_user_id_fkey'), 'users', ['user_id'], ['id'])

    op.create_table('search_interactions',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('search_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('query_text', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('filters_json', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('result_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('selected_node_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('position', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('search_interactions_pkey')),
    schema='analytics'
    )
    with op.batch_alter_table('search_interactions', schema='analytics') as batch_op:
        batch_op.create_index(batch_op.f('ix_search_interactions_user_id'), ['user_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_search_interactions_search_id'), ['search_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_search_interactions_created_at'), ['created_at'], unique=False)

    # ### end Alembic commands ###
